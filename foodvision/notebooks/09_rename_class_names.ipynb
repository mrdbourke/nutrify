{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename classes in true labels\n",
    "\n",
    "Some classes in the true labels are confusing.\n",
    "\n",
    "For example, \"potatoes\" could be \"potato_white\", \"potato_brown\", \"potato_red\" etc...\n",
    "\n",
    "Same with \"onion\" could be \"onion_brown\", \"onion_white\", \"onion_red\" etc...\n",
    "\n",
    "This notebook will serve as a place to rename labels.\n",
    "\n",
    "To start, I'll try \"onion\" -> \"onion_brown\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download original labels from GCP/Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GCP credentials set!\n",
      "[INFO] GCP connection successful! Access to GCP for saving/loading data and models available.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2i59itor) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4cf84d59e042be92b838c19d01dd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">unique-wind-352</strong>: <a href=\"https://wandb.ai/mrdbourke/test_wandb_artifacts_by_reference/runs/2i59itor\" target=\"_blank\">https://wandb.ai/mrdbourke/test_wandb_artifacts_by_reference/runs/2i59itor</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230213_100011-2i59itor/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2i59itor). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/code/nutrify/foodvision/notebooks/wandb/run-20230213_102557-1nd9erw9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mrdbourke/test_wandb_artifacts_by_reference/runs/1nd9erw9\" target=\"_blank\">silver-dragon-355</a></strong> to <a href=\"https://wandb.ai/mrdbourke/test_wandb_artifacts_by_reference\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Labels directory: ./artifacts/food_vision_labels:v22\n",
      "[INFO] Labels path: artifacts/food_vision_labels:v22/annotations.csv\n",
      "[INFO] Working with: 204 classes\n"
     ]
    }
   ],
   "source": [
    "# Append the upper level directory to sys\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Get config\n",
    "from configs.default_config import config\n",
    "\n",
    "args = config\n",
    "\n",
    "# Connect to GCP\n",
    "from utils.gcp_utils import set_gcp_credentials, test_gcp_connection\n",
    "set_gcp_credentials(path_to_key=\"../utils/google-storage-key.json\")\n",
    "test_gcp_connection()\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Initialize a new run\n",
    "from utils.wandb_utils import wandb_load_artifact, wandb_download_and_load_labels\n",
    "\n",
    "notes = \"Changing class names to be more reflective of their food type.\"\n",
    "\n",
    "run = wandb.init(project=args.wandb_project, \n",
    "                 job_type=args.wandb_job_type,\n",
    "                 tags=['manual_photo_upload'],\n",
    "                 notes=notes)\n",
    "\n",
    "annotations, class_names, class_dict, reverse_class_dict, labels_path = wandb_download_and_load_labels(wandb_run=run,\n",
    "wandb_labels_artifact_name=args.wandb_labels_artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>clear_or_confusing</th>\n",
       "      <th>whole_food_or_dish</th>\n",
       "      <th>one_food_or_multiple</th>\n",
       "      <th>label_last_updated_at</th>\n",
       "      <th>label_source</th>\n",
       "      <th>image_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/pain_au_chocolat/4fd7cb42-bd7f-48f1-bfdc-...</td>\n",
       "      <td>4fd7cb42-bd7f-48f1-bfdc-607c2f54b788.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/pain_au_chocolat/2062f52a-781c-4e4f-b8a7-...</td>\n",
       "      <td>2062f52a-781c-4e4f-b8a7-0a108934f453.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/pain_au_chocolat/8003e0f6-37e8-460d-9c14-...</td>\n",
       "      <td>8003e0f6-37e8-460d-9c14-e7c6fe44a37f.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/pain_au_chocolat/839437c8-c643-408f-9f04-...</td>\n",
       "      <td>839437c8-c643-408f-9f04-d0d3bec238c3.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/pain_au_chocolat/ca5c13ff-a535-4b69-9144-...</td>\n",
       "      <td>ca5c13ff-a535-4b69-9144-e06275e01e35.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  test/pain_au_chocolat/4fd7cb42-bd7f-48f1-bfdc-...   \n",
       "1  test/pain_au_chocolat/2062f52a-781c-4e4f-b8a7-...   \n",
       "2  test/pain_au_chocolat/8003e0f6-37e8-460d-9c14-...   \n",
       "3  test/pain_au_chocolat/839437c8-c643-408f-9f04-...   \n",
       "4  test/pain_au_chocolat/ca5c13ff-a535-4b69-9144-...   \n",
       "\n",
       "                                 image_name        class_name  label split  \\\n",
       "0  4fd7cb42-bd7f-48f1-bfdc-607c2f54b788.jpg  pain_au_chocolat    121  test   \n",
       "1  2062f52a-781c-4e4f-b8a7-0a108934f453.jpg  pain_au_chocolat    121  test   \n",
       "2  8003e0f6-37e8-460d-9c14-e7c6fe44a37f.jpg  pain_au_chocolat    121  test   \n",
       "3  839437c8-c643-408f-9f04-d0d3bec238c3.jpg  pain_au_chocolat    121  test   \n",
       "4  ca5c13ff-a535-4b69-9144-e06275e01e35.jpg  pain_au_chocolat    121  test   \n",
       "\n",
       "  clear_or_confusing whole_food_or_dish one_food_or_multiple  \\\n",
       "0                NaN                NaN                  NaN   \n",
       "1                NaN                NaN                  NaN   \n",
       "2                NaN                NaN                  NaN   \n",
       "3                NaN                NaN                  NaN   \n",
       "4                NaN                NaN                  NaN   \n",
       "\n",
       "  label_last_updated_at label_source       image_source  \n",
       "0                   NaN          NaN  internet_download  \n",
       "1                   NaN          NaN  internet_download  \n",
       "2                   NaN          NaN  internet_download  \n",
       "3                   NaN          NaN  internet_download  \n",
       "4                   NaN          NaN  internet_download  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the annotations\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['almond_butter',\n",
       " 'almonds',\n",
       " 'apple_green',\n",
       " 'apple_red',\n",
       " 'apricot',\n",
       " 'asparagus',\n",
       " 'avocado',\n",
       " 'bacon',\n",
       " 'bacon_and_egg_burger',\n",
       " 'bagel',\n",
       " 'baklava',\n",
       " 'banana',\n",
       " 'banana_bread',\n",
       " 'barbecue_sauce',\n",
       " 'beans',\n",
       " 'beef',\n",
       " 'beef_curry',\n",
       " 'beef_mince',\n",
       " 'beef_stir_fry',\n",
       " 'beer',\n",
       " 'beetroot',\n",
       " 'biltong',\n",
       " 'blackberries',\n",
       " 'blueberries',\n",
       " 'bok_choy',\n",
       " 'bread',\n",
       " 'bread_naan',\n",
       " 'broccoli',\n",
       " 'broccolini',\n",
       " 'brownie',\n",
       " 'brussel_sprouts',\n",
       " 'burrito',\n",
       " 'butter',\n",
       " 'cabbage',\n",
       " 'calamari',\n",
       " 'candy',\n",
       " 'capsicum',\n",
       " 'carrot',\n",
       " 'cashews',\n",
       " 'cauliflower',\n",
       " 'celery',\n",
       " 'cheese',\n",
       " 'cheeseburger',\n",
       " 'cherries',\n",
       " 'chicken_breast',\n",
       " 'chicken_thighs',\n",
       " 'chicken_wings',\n",
       " 'chilli',\n",
       " 'chimichurri',\n",
       " 'chocolate',\n",
       " 'chocolate_cake',\n",
       " 'coconut',\n",
       " 'coffee',\n",
       " 'coleslaw',\n",
       " 'cookies',\n",
       " 'coriander',\n",
       " 'corn',\n",
       " 'corn_chips',\n",
       " 'cream',\n",
       " 'croissant',\n",
       " 'crumbed_chicken',\n",
       " 'cucumber',\n",
       " 'cupcake',\n",
       " 'curry_chicken',\n",
       " 'daikon_radish',\n",
       " 'dates',\n",
       " 'donuts',\n",
       " 'dragonfruit',\n",
       " 'eggplant',\n",
       " 'eggs',\n",
       " 'enoki_mushroom',\n",
       " 'fennel',\n",
       " 'figs',\n",
       " 'french_toast',\n",
       " 'fried_rice',\n",
       " 'fries',\n",
       " 'fruit_juice',\n",
       " 'garlic',\n",
       " 'garlic_bread',\n",
       " 'ginger',\n",
       " 'goji_berries',\n",
       " 'granola',\n",
       " 'grapefruit',\n",
       " 'grapes',\n",
       " 'green_beans',\n",
       " 'guacamole',\n",
       " 'guava',\n",
       " 'gyoza',\n",
       " 'ham',\n",
       " 'honey',\n",
       " 'hot_chocolate',\n",
       " 'ice_coffee',\n",
       " 'ice_cream',\n",
       " 'iceberg_lettuce',\n",
       " 'jerusalem_artichoke',\n",
       " 'kale',\n",
       " 'karaage_chicken',\n",
       " 'kimchi',\n",
       " 'kiwi_fruit',\n",
       " 'lamb_chops',\n",
       " 'leek',\n",
       " 'lemon',\n",
       " 'lentils',\n",
       " 'lettuce',\n",
       " 'lime',\n",
       " 'lychee',\n",
       " 'mandarin',\n",
       " 'mango',\n",
       " 'maple_syrup',\n",
       " 'mashed_potato',\n",
       " 'mayonnaise',\n",
       " 'milk',\n",
       " 'miso_soup',\n",
       " 'mushrooms',\n",
       " 'nectarines',\n",
       " 'noodles',\n",
       " 'nuts',\n",
       " 'olive_oil',\n",
       " 'olives',\n",
       " 'omelette',\n",
       " 'onion_brown',\n",
       " 'onion_green',\n",
       " 'onion_red',\n",
       " 'onion_white',\n",
       " 'orange',\n",
       " 'orange_juice',\n",
       " 'oysters',\n",
       " 'pain_au_chocolat',\n",
       " 'pancakes',\n",
       " 'papaya',\n",
       " 'parsley',\n",
       " 'parsnips',\n",
       " 'passionfruit',\n",
       " 'pasta',\n",
       " 'pawpaw',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'peas',\n",
       " 'pickles',\n",
       " 'pineapple',\n",
       " 'pizza',\n",
       " 'plum',\n",
       " 'pomegranate',\n",
       " 'popcorn',\n",
       " 'pork_belly',\n",
       " 'pork_chop',\n",
       " 'pork_loins',\n",
       " 'porridge',\n",
       " 'potato_bake',\n",
       " 'potato_brown',\n",
       " 'potato_chips',\n",
       " 'potato_scallop',\n",
       " 'potato_white',\n",
       " 'prawns',\n",
       " 'pumpkin',\n",
       " 'radish',\n",
       " 'ramen',\n",
       " 'raspberries',\n",
       " 'red_wine',\n",
       " 'rhubarb',\n",
       " 'rice',\n",
       " 'roast_beef',\n",
       " 'roast_pork',\n",
       " 'roast_potatoes',\n",
       " 'rockmelon',\n",
       " 'rosemary',\n",
       " 'salad',\n",
       " 'salami',\n",
       " 'salmon',\n",
       " 'salsa',\n",
       " 'salt',\n",
       " 'sandwich',\n",
       " 'sardines',\n",
       " 'sausage_roll',\n",
       " 'sausages',\n",
       " 'scrambled_eggs',\n",
       " 'seaweed',\n",
       " 'shallots',\n",
       " 'snow_peas',\n",
       " 'soda',\n",
       " 'soy_sauce',\n",
       " 'spaghetti_bolognese',\n",
       " 'spinach',\n",
       " 'sports_drink',\n",
       " 'squash',\n",
       " 'starfruit',\n",
       " 'steak',\n",
       " 'strawberries',\n",
       " 'sushi',\n",
       " 'sweet_potato',\n",
       " 'tacos',\n",
       " 'tamarillo',\n",
       " 'taro',\n",
       " 'tea',\n",
       " 'toast',\n",
       " 'tofu',\n",
       " 'tomato',\n",
       " 'tomato_chutney',\n",
       " 'tomato_sauce',\n",
       " 'turnip',\n",
       " 'watermelon',\n",
       " 'white_wine',\n",
       " 'yoghurt',\n",
       " 'zucchini']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the class names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class_names = ['apple_green',\n",
    " 'apple_red',\n",
    " 'avocado',\n",
    " 'bacon',\n",
    " 'banana',\n",
    " 'banana_bread',\n",
    " 'beef_stir_fry',\n",
    " 'biltong',\n",
    " 'blueberries',\n",
    " 'bread',\n",
    " 'bread_naan',\n",
    " 'broccoli',\n",
    " 'broccolini',\n",
    " 'butter',\n",
    " 'capsicum',\n",
    " 'carrot',\n",
    " 'cheese',\n",
    " 'cheeseburger',\n",
    " 'cherries',\n",
    " 'chicken_thighs',\n",
    " 'coffee',\n",
    " 'coleslaw',\n",
    " 'corn',\n",
    " 'cucumber',\n",
    " 'curry_chicken',\n",
    " 'dates',\n",
    " 'eggs',\n",
    " 'fries',\n",
    " 'garlic',\n",
    " 'grapes',\n",
    " 'green_beans',\n",
    " 'honey',\n",
    " 'ice_coffee',\n",
    " 'kiwi_fruit',\n",
    " 'lemon',\n",
    " 'lime',\n",
    " 'lychee',\n",
    " 'mango',\n",
    " 'milk',\n",
    " 'mushrooms',\n",
    " 'nectarines',\n",
    " 'omelette',\n",
    " 'onion_brown',\n",
    " 'onion_red',\n",
    " 'onion_white',\n",
    " 'orange_juice',\n",
    " 'passionfruit',\n",
    " 'peach',\n",
    " 'plum',\n",
    " 'pomegranate',\n",
    " 'porridge',\n",
    " 'potato_bake',\n",
    " 'potato_brown',\n",
    " 'potato_white',\n",
    " 'pumpkin',\n",
    " 'rice',\n",
    " 'roast_pork',\n",
    " 'roast_potatoes',\n",
    " 'steak',\n",
    " 'tea',\n",
    " 'tomato',\n",
    " 'watermelon',\n",
    " 'yoghurt',\n",
    " 'zucchini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the classes that are missing\n",
    "missing_class_names = list(set(new_class_names) - set(class_names))\n",
    "missing_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"onion_red\" in class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with class name 'lychee': 0\n",
      "Number of rows with class name 'bread_naan': 0\n",
      "Number of rows with class name 'apple_green': 0\n",
      "Number of rows with class name 'curry_chicken': 0\n",
      "Number of rows with class name 'potato_white': 0\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the original annotations\n",
    "original_annotations = annotations.copy()\n",
    "\n",
    "# Find how many of the original_annotations have the class_name onion\n",
    "for class_name in missing_class_names:\n",
    "    print(f\"Number of rows with class name '{class_name}': {len(original_annotations[original_annotations['class_name'] == class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to similarity match the class names (e.g. code which string is most like another string)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import dot_score\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_list_of_classes(class_names: list, model: SentenceTransformer):\n",
    "    \"\"\"\n",
    "    Embeds a list of class names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map the class_name to the embedding\n",
    "    class_name_to_embedding = {class_name: embedding for class_name, embedding in zip(class_names, model.encode(class_names))}\n",
    "\n",
    "    return class_name_to_embedding\n",
    "\n",
    "class_name_embeddings = embed_list_of_classes(class_names, model = model)\n",
    "\n",
    "# Create a function to similarity match the class names (e.g. code which string is most like another string)\n",
    "def find_most_similar_class_name(target_class_name, class_name_embedding_dict):\n",
    "    \"\"\"\n",
    "    Finds the most similar class name to the class_name provided.\n",
    "    \"\"\"\n",
    "    # Get the embedding of the target_class_name\n",
    "    target_class_name_embedding = model.encode([target_class_name])[0]\n",
    "\n",
    "    # Find the top-3 most similar class_name\n",
    "    most_similar_class_names = sorted(class_name_embedding_dict.keys(), key=lambda key: dot_score(class_name_embedding_dict[key], target_class_name_embedding), reverse=True)[:3]\n",
    "    # most_similar_class_name = max(class_name_embedding_dict.keys(), key=lambda key: dot_score(class_name_embedding_dict[key], target_class_name_embedding))\n",
    "\n",
    "    return most_similar_class_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to string match the class names (e.g. code which string is most like another string)\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def match_string_via_sequence_matcher(target_string, string_list):\n",
    "    \"\"\"\n",
    "    Finds the most similar string to the string provided.\n",
    "    \"\"\"\n",
    "    # Find the top-3 most similar class_name\n",
    "    most_similar_strings = sorted(string_list, key=lambda string: SequenceMatcher(None, string, target_string).ratio(), reverse=True)[:3]\n",
    "\n",
    "    return most_similar_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'maple_syrup', 'onion_green']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_string_via_sequence_matcher(\"apple_green\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_name_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar class names to 'lychee' | Embedding match: ['rosemary', 'white_wine', 'beetroot'] | String match: ['cheese', 'leek', 'cherries']\n",
      "Similar class names to 'bread_naan' | Embedding match: ['banana_bread', 'bread', 'garlic_bread'] | String match: ['bread', 'red_wine', 'beans']\n",
      "Similar class names to 'apple_green' | Embedding match: ['onion_green', 'green_beans', 'fruit_juice'] | String match: ['apple', 'maple_syrup', 'onion_green']\n",
      "Similar class names to 'apple_red' | Embedding match: ['onion_red', 'fruit_juice', 'red_wine'] | String match: ['apple', 'maple_syrup', 'garlic_bread']\n",
      "Similar class names to 'curry_chicken' | Embedding match: ['beef_curry', 'chicken_breast', 'karaage_chicken'] | String match: ['crumbed_chicken', 'karaage_chicken', 'chicken_wings']\n",
      "Similar class names to 'potato_white' | Embedding match: ['sweet_potato', 'potato_bake', 'mashed_potato'] | String match: ['potato_chips', 'potatoes', 'onion_white']\n",
      "Similar class names to 'potato_brown' | Embedding match: ['sweet_potato', 'potato_bake', 'onion_brown'] | String match: ['onion_brown', 'potato_bake', 'potato_scallop']\n"
     ]
    }
   ],
   "source": [
    "# Find the most similar class names to each missing class\n",
    "for class_name in missing_class_names:\n",
    "    top_3_similar_class_embeddings = find_most_similar_class_name(class_name, class_name_embeddings)\n",
    "    top_3_similar_class_string_matching = match_string_via_sequence_matcher(class_name, class_names)\n",
    "    print(f\"Similar class names to '{class_name}' | Embedding match: {top_3_similar_class_embeddings} | String match: {top_3_similar_class_string_matching}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create updated_annotations\n",
    "updated_annotations = original_annotations.copy()\n",
    "\n",
    "# Rename apple -> apple_red\n",
    "updated_annotations.loc[updated_annotations['class_name'] == 'apple', 'class_name'] = 'apple_red'\n",
    "\n",
    "# Rename potatoes -> potato_brown\n",
    "updated_annotations.loc[updated_annotations['class_name'] == 'potatoes', 'class_name'] = 'potato_brown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next\n",
    "# See how many differences there are between updated_annotations and original_annotations\n",
    "# Upload the new annotations to GCP\n",
    "# Merge new images if their class_name is in the existing class_names (of the new labels)\n",
    "# Upload images to GCP\n",
    "# Track images and labels in W&B\n",
    "# Train a model and evaluate on new data\n",
    "# Make a way in data_loader.py to load data from specific sources, e.g. manual_download etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: move this into utils folder \n",
    "from utils.misc import check_for_differences_between_df\n",
    "\n",
    "num_differences = check_for_differences_between_df(updated_annotations, original_annotations)\n",
    "num_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename',\n",
       " 'image_name',\n",
       " 'class_name',\n",
       " 'label',\n",
       " 'split',\n",
       " 'clear_or_confusing',\n",
       " 'whole_food_or_dish',\n",
       " 'one_food_or_multiple',\n",
       " 'label_last_updated_at',\n",
       " 'label_source',\n",
       " 'image_source']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.annotations_columns_to_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Exporting the following columns to updated_annotations.csv: ['filename', 'image_name', 'class_name', 'label', 'split', 'clear_or_confusing', 'whole_food_or_dish', 'one_food_or_multiple', 'label_last_updated_at', 'label_source', 'image_source']\n",
      "[INFO] 185 changes to annotations.csv, updated label files and original annotations are different, saving the updated annotations.csv\n",
      "[INFO] Uploading updated_annotations.csv to updated_annotations.csv...\n",
      "[INFO] Connected to Google Storage bucket: food_vision_bucket_with_object_versioning\n",
      "[INFO] File updated_annotations.csv uploaded to food_vision_bucket_with_object_versioning/updated_annotations.csv.\n",
      "[INFO] File size: 3690016 bytes\n",
      "[INFO] Blob annotations.csv has been renamed to old_annotations/2023-02-13_09-54-16_old_annotations.csv\n",
      "[INFO] Blob updated_annotations.csv has been renamed to annotations.csv\n",
      "[INFO] Logging 'food_vision_labels' from 'gs://food_vision_bucket_with_object_versioning/annotations.csv' to Weights & Biases...\n"
     ]
    }
   ],
   "source": [
    "# Upload the updated annotations to Google Storage and track the changes\n",
    "import os\n",
    "from utils.gcp_utils import upload_to_gs, rename_blob, delete_blob\n",
    "from utils.wandb_utils import wandb_add_artifact_with_reference\n",
    "from utils.misc import get_now_time\n",
    "\n",
    "UPDATED_ANNOTATIONS_TARGET_FILENAME = \"updated_annotations.csv\"\n",
    "ORIGINAL_ANNOTATIONS_TARGET_FILENAME = \"annotations.csv\"\n",
    "GS_BUCKET_NAME = config.gs_bucket_name\n",
    "\n",
    "# Export the updated annotations to a CSV\n",
    "columns_to_export = config.annotations_columns_to_export\n",
    "print(f\"[INFO] Exporting the following columns to {UPDATED_ANNOTATIONS_TARGET_FILENAME}: {columns_to_export}\")\n",
    "\n",
    "# TODO: Check if the updated_annotations_reset_index and the original_annotations actually differ, if so save them and upload them, else exit\n",
    "if num_differences > 0:\n",
    "    print(f\"[INFO] {num_differences} changes to annotations.csv, updated label files and original annotations are different, saving the updated annotations.csv\")\n",
    "\n",
    "    # Export the updated_annotations_reset_index to a csv\n",
    "    updated_annotations[columns_to_export].to_csv(UPDATED_ANNOTATIONS_TARGET_FILENAME, index=False)\n",
    "\n",
    "    # Upload the updated CSV to Google Storage\n",
    "    upload_to_gs(bucket_name=GS_BUCKET_NAME, \n",
    "                 source_file_name=UPDATED_ANNOTATIONS_TARGET_FILENAME, \n",
    "                 destination_blob_name=UPDATED_ANNOTATIONS_TARGET_FILENAME)\n",
    "\n",
    "    # Rename the old CSV on Google Storage\n",
    "    bucket_to_move_old_annotations_to = \"old_annotations\"\n",
    "    name_to_rename_old_annotations = os.path.join(bucket_to_move_old_annotations_to, f\"{get_now_time()}_old_annotations.csv\")\n",
    "\n",
    "    rename_blob(bucket_name=GS_BUCKET_NAME,\n",
    "                blob_name=ORIGINAL_ANNOTATIONS_TARGET_FILENAME,\n",
    "                new_name=name_to_rename_old_annotations)\n",
    "\n",
    "    # Rename the \"updated_annotations.csv\" on Google Storage to \"annotations.csv\" \n",
    "    rename_blob(bucket_name=GS_BUCKET_NAME,\n",
    "                blob_name=UPDATED_ANNOTATIONS_TARGET_FILENAME,\n",
    "                new_name=ORIGINAL_ANNOTATIONS_TARGET_FILENAME)\n",
    "\n",
    "    # Track the changes in the annotations with Weights & Biases\n",
    "    annotations_path_on_gcs = f\"gs://{GS_BUCKET_NAME}/{ORIGINAL_ANNOTATIONS_TARGET_FILENAME}\"\n",
    "    wandb_add_artifact_with_reference(wandb_run=run,\n",
    "                                      artifact_name=\"food_vision_labels\",\n",
    "                                      artifact_type=\"labels\",\n",
    "                                      description=\"Labels for FoodVision project\",\n",
    "                                      reference_path=annotations_path_on_gcs)\n",
    "else:\n",
    "    print(\"[INFO] No changes to annotations.csv, updated label files and original annotations are the same, try fixing/updating the label files and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export class_dict to JSON\n",
    "import json\n",
    "with open(\"class_dict.json\", \"w\") as f:\n",
    "    json.dump(class_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn class_dict into a DataFrame\n",
    "class_dict_df = pd.DataFrame(class_dict.items(), columns=['class_name', 'class_id'])\n",
    "\n",
    "# Export to csv\n",
    "class_dict_df.to_csv(\"class_dict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
