{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename classes in true labels\n",
    "\n",
    "Some classes in the true labels are confusing.\n",
    "\n",
    "For example, \"potatoes\" could be \"potato_white\", \"potato_brown\", \"potato_red\" etc...\n",
    "\n",
    "Same with \"onion\" could be \"onion_brown\", \"onion_white\", \"onion_red\" etc...\n",
    "\n",
    "This notebook will serve as a place to rename labels.\n",
    "\n",
    "To start, I'll try \"onion\" -> \"onion_brown\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download original labels from GCP/Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] GCP credentials set!\n",
      "[INFO] GCP connection successful! Access to GCP for saving/loading data and models available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmrdbourke\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/code/nutrify/foodvision/notebooks/wandb/run-20230215_162442-1ay2u8n7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mrdbourke/test_wandb_artifacts_by_reference/runs/1ay2u8n7\" target=\"_blank\">sweet-admirer-384</a></strong> to <a href=\"https://wandb.ai/mrdbourke/test_wandb_artifacts_by_reference\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Labels directory: ./artifacts/food_vision_labels:v26\n",
      "[INFO] Labels path: artifacts/food_vision_labels:v26/annotations.csv\n",
      "[INFO] Working with: 208 classes\n"
     ]
    }
   ],
   "source": [
    "# Append the upper level directory to sys\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Get config\n",
    "from configs.default_config import config\n",
    "\n",
    "args = config\n",
    "\n",
    "# Connect to GCP\n",
    "from utils.gcp_utils import set_gcp_credentials, test_gcp_connection\n",
    "set_gcp_credentials(path_to_key=\"../utils/google-storage-key.json\")\n",
    "test_gcp_connection()\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Initialize a new run\n",
    "from utils.wandb_utils import wandb_load_artifact, wandb_download_and_load_labels\n",
    "\n",
    "notes = \"Changing class names to be more reflective of their food type.\"\n",
    "\n",
    "run = wandb.init(project=args.wandb_project, \n",
    "                 job_type=args.wandb_job_type,\n",
    "                 tags=['manual_photo_upload'],\n",
    "                 notes=notes)\n",
    "\n",
    "annotations, class_names, class_dict, reverse_class_dict, labels_path = wandb_download_and_load_labels(wandb_run=run,\n",
    "wandb_labels_artifact_name=args.wandb_labels_artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>clear_or_confusing</th>\n",
       "      <th>whole_food_or_dish</th>\n",
       "      <th>one_food_or_multiple</th>\n",
       "      <th>label_last_updated_at</th>\n",
       "      <th>label_source</th>\n",
       "      <th>image_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/pain_au_chocolat/4fd7cb42-bd7f-48f1-bfdc-...</td>\n",
       "      <td>4fd7cb42-bd7f-48f1-bfdc-607c2f54b788.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/pain_au_chocolat/2062f52a-781c-4e4f-b8a7-...</td>\n",
       "      <td>2062f52a-781c-4e4f-b8a7-0a108934f453.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/pain_au_chocolat/8003e0f6-37e8-460d-9c14-...</td>\n",
       "      <td>8003e0f6-37e8-460d-9c14-e7c6fe44a37f.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/pain_au_chocolat/839437c8-c643-408f-9f04-...</td>\n",
       "      <td>839437c8-c643-408f-9f04-d0d3bec238c3.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/pain_au_chocolat/ca5c13ff-a535-4b69-9144-...</td>\n",
       "      <td>ca5c13ff-a535-4b69-9144-e06275e01e35.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>121</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  test/pain_au_chocolat/4fd7cb42-bd7f-48f1-bfdc-...   \n",
       "1  test/pain_au_chocolat/2062f52a-781c-4e4f-b8a7-...   \n",
       "2  test/pain_au_chocolat/8003e0f6-37e8-460d-9c14-...   \n",
       "3  test/pain_au_chocolat/839437c8-c643-408f-9f04-...   \n",
       "4  test/pain_au_chocolat/ca5c13ff-a535-4b69-9144-...   \n",
       "\n",
       "                                 image_name        class_name  label split  \\\n",
       "0  4fd7cb42-bd7f-48f1-bfdc-607c2f54b788.jpg  pain_au_chocolat    121  test   \n",
       "1  2062f52a-781c-4e4f-b8a7-0a108934f453.jpg  pain_au_chocolat    121  test   \n",
       "2  8003e0f6-37e8-460d-9c14-e7c6fe44a37f.jpg  pain_au_chocolat    121  test   \n",
       "3  839437c8-c643-408f-9f04-d0d3bec238c3.jpg  pain_au_chocolat    121  test   \n",
       "4  ca5c13ff-a535-4b69-9144-e06275e01e35.jpg  pain_au_chocolat    121  test   \n",
       "\n",
       "  clear_or_confusing whole_food_or_dish one_food_or_multiple  \\\n",
       "0                NaN                NaN                  NaN   \n",
       "1                NaN                NaN                  NaN   \n",
       "2                NaN                NaN                  NaN   \n",
       "3                NaN                NaN                  NaN   \n",
       "4                NaN                NaN                  NaN   \n",
       "\n",
       "  label_last_updated_at label_source       image_source  \n",
       "0                   NaN          NaN  internet_download  \n",
       "1                   NaN          NaN  internet_download  \n",
       "2                   NaN          NaN  internet_download  \n",
       "3                   NaN          NaN  internet_download  \n",
       "4                   NaN          NaN  internet_download  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the annotations\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if reverse_class_dict is the same as the reverse of class_dict\n",
    "reverse_class_dict == {v: k for k, v in class_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if class_names == class_dict.keys()\n",
    "class_names == sorted(list(reverse_class_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are class_names and list(reverse_class_dict.keys()) different?\n",
    "for i, (class_name, class_dict_key) in enumerate(zip(class_names, sorted(list(reverse_class_dict.keys())))):\n",
    "    if class_name != class_dict_key:\n",
    "        print(f\"Class name {class_name} at index {i} is different from class_dict_key {class_dict_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['almond_butter',\n",
       " 'almonds',\n",
       " 'apple_green',\n",
       " 'apple_red',\n",
       " 'apricot',\n",
       " 'asparagus',\n",
       " 'avocado',\n",
       " 'bacon',\n",
       " 'bacon_and_egg_burger',\n",
       " 'bagel',\n",
       " 'baklava',\n",
       " 'banana',\n",
       " 'banana_bread',\n",
       " 'barbecue_sauce',\n",
       " 'beans',\n",
       " 'beef',\n",
       " 'beef_curry',\n",
       " 'beef_mince',\n",
       " 'beef_stir_fry',\n",
       " 'beer',\n",
       " 'beetroot',\n",
       " 'biltong',\n",
       " 'blackberries',\n",
       " 'blueberries',\n",
       " 'bok_choy',\n",
       " 'bread',\n",
       " 'bread_naan',\n",
       " 'broccoli',\n",
       " 'broccolini',\n",
       " 'brownie',\n",
       " 'brussel_sprouts',\n",
       " 'burrito',\n",
       " 'butter',\n",
       " 'cabbage',\n",
       " 'calamari',\n",
       " 'candy',\n",
       " 'capsicum',\n",
       " 'carrot',\n",
       " 'cashews',\n",
       " 'cauliflower',\n",
       " 'celery',\n",
       " 'cheese',\n",
       " 'cheeseburger',\n",
       " 'cherries',\n",
       " 'chicken_breast',\n",
       " 'chicken_thighs',\n",
       " 'chicken_wings',\n",
       " 'chilli',\n",
       " 'chimichurri',\n",
       " 'chocolate',\n",
       " 'chocolate_cake',\n",
       " 'coconut',\n",
       " 'coffee',\n",
       " 'coleslaw',\n",
       " 'cookies',\n",
       " 'coriander',\n",
       " 'corn',\n",
       " 'corn_chips',\n",
       " 'cream',\n",
       " 'croissant',\n",
       " 'crumbed_chicken',\n",
       " 'cucumber',\n",
       " 'cupcake',\n",
       " 'curry_chicken',\n",
       " 'daikon_radish',\n",
       " 'dates',\n",
       " 'donuts',\n",
       " 'dragonfruit',\n",
       " 'eggplant',\n",
       " 'eggs',\n",
       " 'enoki_mushroom',\n",
       " 'fennel',\n",
       " 'figs',\n",
       " 'french_toast',\n",
       " 'fried_rice',\n",
       " 'fries',\n",
       " 'fruit_juice',\n",
       " 'fruit_smoothie',\n",
       " 'garlic',\n",
       " 'garlic_bread',\n",
       " 'ginger',\n",
       " 'goji_berries',\n",
       " 'granola',\n",
       " 'grapefruit',\n",
       " 'grapes_black',\n",
       " 'grapes_red',\n",
       " 'grapes_white',\n",
       " 'green_beans',\n",
       " 'guacamole',\n",
       " 'guava',\n",
       " 'gyoza',\n",
       " 'ham',\n",
       " 'honey',\n",
       " 'hot_chocolate',\n",
       " 'ice_coffee',\n",
       " 'ice_cream',\n",
       " 'iceberg_lettuce',\n",
       " 'jerusalem_artichoke',\n",
       " 'kale',\n",
       " 'karaage_chicken',\n",
       " 'kimchi',\n",
       " 'kiwi_fruit',\n",
       " 'lamb_chops',\n",
       " 'leek',\n",
       " 'lemon',\n",
       " 'lentils',\n",
       " 'lettuce',\n",
       " 'lime',\n",
       " 'lychee',\n",
       " 'mandarin',\n",
       " 'mango',\n",
       " 'maple_syrup',\n",
       " 'mashed_potato',\n",
       " 'mayonnaise',\n",
       " 'milk',\n",
       " 'miso_soup',\n",
       " 'mushrooms',\n",
       " 'nectarines',\n",
       " 'noodles',\n",
       " 'nuts',\n",
       " 'olive_oil',\n",
       " 'olives',\n",
       " 'omelette',\n",
       " 'onion_brown',\n",
       " 'onion_green',\n",
       " 'onion_red',\n",
       " 'onion_white',\n",
       " 'orange',\n",
       " 'orange_juice',\n",
       " 'oysters',\n",
       " 'pain_au_chocolat',\n",
       " 'pancakes',\n",
       " 'papaya',\n",
       " 'parsley',\n",
       " 'parsnips',\n",
       " 'passionfruit',\n",
       " 'pasta',\n",
       " 'pawpaw',\n",
       " 'peach',\n",
       " 'pear',\n",
       " 'peas',\n",
       " 'pickles',\n",
       " 'pineapple',\n",
       " 'pizza',\n",
       " 'plum',\n",
       " 'pomegranate',\n",
       " 'popcorn',\n",
       " 'pork_belly',\n",
       " 'pork_chop',\n",
       " 'pork_loins',\n",
       " 'porridge',\n",
       " 'potato_bake',\n",
       " 'potato_brown',\n",
       " 'potato_chips',\n",
       " 'potato_scallop',\n",
       " 'potato_white',\n",
       " 'prawns',\n",
       " 'prosciutto',\n",
       " 'pumpkin',\n",
       " 'radish',\n",
       " 'ramen',\n",
       " 'raspberries',\n",
       " 'red_wine',\n",
       " 'rhubarb',\n",
       " 'rice',\n",
       " 'roast_beef',\n",
       " 'roast_pork',\n",
       " 'roast_potatoes',\n",
       " 'rockmelon',\n",
       " 'rosemary',\n",
       " 'salad',\n",
       " 'salami',\n",
       " 'salmon',\n",
       " 'salsa',\n",
       " 'salt',\n",
       " 'sandwich',\n",
       " 'sardines',\n",
       " 'sausage_roll',\n",
       " 'sausages',\n",
       " 'scrambled_eggs',\n",
       " 'seaweed',\n",
       " 'shallots',\n",
       " 'snow_peas',\n",
       " 'soda',\n",
       " 'soy_sauce',\n",
       " 'spaghetti_bolognese',\n",
       " 'spinach',\n",
       " 'sports_drink',\n",
       " 'squash',\n",
       " 'starfruit',\n",
       " 'steak',\n",
       " 'strawberries',\n",
       " 'sushi',\n",
       " 'sweet_potato',\n",
       " 'tacos',\n",
       " 'tamarillo',\n",
       " 'taro',\n",
       " 'tea',\n",
       " 'toast',\n",
       " 'tofu',\n",
       " 'tomato',\n",
       " 'tomato_chutney',\n",
       " 'tomato_sauce',\n",
       " 'turnip',\n",
       " 'watermelon',\n",
       " 'white_wine',\n",
       " 'yoghurt',\n",
       " 'zucchini']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the class names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"onion_red\" in class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with class name 'fruit_smoothie': 56\n",
      "Number of rows with class name 'grapes_black': 132\n",
      "Number of rows with class name 'grapes_red': 216\n",
      "Number of rows with class name 'grapes_white': 137\n",
      "Number of rows with class name 'prosciutto': 62\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the original annotations\n",
    "original_annotations = annotations.copy()\n",
    "\n",
    "missing_class_names = ['fruit_smoothie', 'grapes_black', 'grapes_red', 'grapes_white', 'prosciutto']\n",
    "\n",
    "# Find how many of the original_annotations have the class_name onion\n",
    "for class_name in missing_class_names:\n",
    "    print(f\"Number of rows with class name '{class_name}': {len(original_annotations[original_annotations['class_name'] == class_name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to similarity match the class names (e.g. code which string is most like another string)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import dot_score\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_list_of_classes(class_names: list, model: SentenceTransformer):\n",
    "    \"\"\"\n",
    "    Embeds a list of class names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map the class_name to the embedding\n",
    "    class_name_to_embedding = {class_name: embedding for class_name, embedding in zip(class_names, model.encode(class_names))}\n",
    "\n",
    "    return class_name_to_embedding\n",
    "\n",
    "class_name_embeddings = embed_list_of_classes(class_names, model = model)\n",
    "\n",
    "# Create a function to similarity match the class names (e.g. code which string is most like another string)\n",
    "def find_most_similar_class_name(target_class_name, class_name_embedding_dict):\n",
    "    \"\"\"\n",
    "    Finds the most similar class name to the class_name provided.\n",
    "    \"\"\"\n",
    "    # Get the embedding of the target_class_name\n",
    "    target_class_name_embedding = model.encode([target_class_name])[0]\n",
    "\n",
    "    # Find the top-3 most similar class_name\n",
    "    most_similar_class_names = sorted(class_name_embedding_dict.keys(), key=lambda key: dot_score(class_name_embedding_dict[key], target_class_name_embedding), reverse=True)[:3]\n",
    "    # most_similar_class_name = max(class_name_embedding_dict.keys(), key=lambda key: dot_score(class_name_embedding_dict[key], target_class_name_embedding))\n",
    "\n",
    "    return most_similar_class_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to string match the class names (e.g. code which string is most like another string)\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def match_string_via_sequence_matcher(target_string, string_list):\n",
    "    \"\"\"\n",
    "    Finds the most similar string to the string provided.\n",
    "    \"\"\"\n",
    "    # Find the top-3 most similar class_name\n",
    "    most_similar_strings = sorted(string_list, key=lambda string: SequenceMatcher(None, string, target_string).ratio(), reverse=True)[:3]\n",
    "\n",
    "    return most_similar_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grapes_red', 'apple_red', 'grapes_white']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_string_via_sequence_matcher(\"grapes_red\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_name_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar class names to 'fruit_smoothie' | Embedding match: ['fruit_smoothie', 'fruit_juice', 'kiwi_fruit'] | String match: ['fruit_smoothie', 'fruit_juice', 'starfruit']\n",
      "Similar class names to 'grapes_black' | Embedding match: ['grapes_black', 'grapes_white', 'grapes_red'] | String match: ['grapes_black', 'grapes_red', 'grapes_white']\n",
      "Similar class names to 'grapes_red' | Embedding match: ['grapes_red', 'grapes_black', 'grapes_white'] | String match: ['grapes_red', 'apple_red', 'grapes_white']\n",
      "Similar class names to 'grapes_white' | Embedding match: ['grapes_white', 'grapes_black', 'grapes_red'] | String match: ['grapes_white', 'grapes_red', 'grapefruit']\n",
      "Similar class names to 'prosciutto' | Embedding match: ['prosciutto', 'pasta', 'beef'] | String match: ['prosciutto', 'roast_pork', 'roast_potatoes']\n"
     ]
    }
   ],
   "source": [
    "# Find the most similar class names to each missing class\n",
    "for class_name in missing_class_names:\n",
    "    top_3_similar_class_embeddings = find_most_similar_class_name(class_name, class_name_embeddings)\n",
    "    top_3_similar_class_string_matching = match_string_via_sequence_matcher(class_name, class_names)\n",
    "    print(f\"Similar class names to '{class_name}' | Embedding match: {top_3_similar_class_embeddings} | String match: {top_3_similar_class_string_matching}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create updated_annotations\n",
    "updated_annotations = original_annotations.copy()\n",
    "\n",
    "# Randomly rename all rows with \"grapes\" to one of the following: grapes_red, grapes_white, grapes_black\n",
    "# Find all rows which have the name \"grapes\"\n",
    "grapes_rows = updated_annotations[updated_annotations['class_name'] == \"grapes\"]\n",
    "\n",
    "# Get the indices of the rows which have the name \"grapes\"\n",
    "grapes_indices = grapes_rows.index\n",
    "\n",
    "# Rename all rows with the name \"grapes\" to one of: grapes_red, grapes_white, grapes_black\n",
    "updated_annotations.loc[grapes_indices, 'class_name'] = np.random.choice([\"grapes_red\", \"grapes_white\", \"grapes_black\"], size=len(grapes_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the reverse class dict to the updated_annotations\n",
    "updated_annotations['label'] = updated_annotations['class_name'].map(reverse_class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(updated_annotations.class_name.unique()), len(updated_annotations.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the class names in updated_annotations in list\n",
    "updated_class_names_list = sorted(list(updated_annotations.class_name.unique()))\n",
    "\n",
    "# Map all updated_class_names_list to a dictionary of sequential integers\n",
    "reverse_class_dict_updated = {class_name: i for i, class_name in enumerate(updated_class_names_list)}\n",
    "\n",
    "# Apply the reverse_class_dict_updated to the updated_annotations\n",
    "updated_annotations['label'] = updated_annotations['class_name'].map(reverse_class_dict_updated)\n",
    "\n",
    "# Show the unique labels of the updated_annotations in order\n",
    "np.sort(updated_annotations.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next\n",
    "# See how many differences there are between updated_annotations and original_annotations\n",
    "# Upload the new annotations to GCP\n",
    "# Merge new images if their class_name is in the existing class_names (of the new labels)\n",
    "# Upload images to GCP\n",
    "# Track images and labels in W&B\n",
    "# Train a model and evaluate on new data\n",
    "# Make a way in data_loader.py to load data from specific sources, e.g. manual_download etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40325"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: move this into utils folder \n",
    "from utils.misc import check_for_differences_between_df\n",
    "\n",
    "num_differences = check_for_differences_between_df(updated_annotations, original_annotations)\n",
    "num_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>image_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>clear_or_confusing</th>\n",
       "      <th>whole_food_or_dish</th>\n",
       "      <th>one_food_or_multiple</th>\n",
       "      <th>label_last_updated_at</th>\n",
       "      <th>label_source</th>\n",
       "      <th>image_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/pain_au_chocolat/4fd7cb42-bd7f-48f1-bfdc-...</td>\n",
       "      <td>4fd7cb42-bd7f-48f1-bfdc-607c2f54b788.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>130</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/pain_au_chocolat/2062f52a-781c-4e4f-b8a7-...</td>\n",
       "      <td>2062f52a-781c-4e4f-b8a7-0a108934f453.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>130</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/pain_au_chocolat/8003e0f6-37e8-460d-9c14-...</td>\n",
       "      <td>8003e0f6-37e8-460d-9c14-e7c6fe44a37f.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>130</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/pain_au_chocolat/839437c8-c643-408f-9f04-...</td>\n",
       "      <td>839437c8-c643-408f-9f04-d0d3bec238c3.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>130</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/pain_au_chocolat/ca5c13ff-a535-4b69-9144-...</td>\n",
       "      <td>ca5c13ff-a535-4b69-9144-e06275e01e35.jpg</td>\n",
       "      <td>pain_au_chocolat</td>\n",
       "      <td>130</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>internet_download</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  test/pain_au_chocolat/4fd7cb42-bd7f-48f1-bfdc-...   \n",
       "1  test/pain_au_chocolat/2062f52a-781c-4e4f-b8a7-...   \n",
       "2  test/pain_au_chocolat/8003e0f6-37e8-460d-9c14-...   \n",
       "3  test/pain_au_chocolat/839437c8-c643-408f-9f04-...   \n",
       "4  test/pain_au_chocolat/ca5c13ff-a535-4b69-9144-...   \n",
       "\n",
       "                                 image_name        class_name  label split  \\\n",
       "0  4fd7cb42-bd7f-48f1-bfdc-607c2f54b788.jpg  pain_au_chocolat    130  test   \n",
       "1  2062f52a-781c-4e4f-b8a7-0a108934f453.jpg  pain_au_chocolat    130  test   \n",
       "2  8003e0f6-37e8-460d-9c14-e7c6fe44a37f.jpg  pain_au_chocolat    130  test   \n",
       "3  839437c8-c643-408f-9f04-d0d3bec238c3.jpg  pain_au_chocolat    130  test   \n",
       "4  ca5c13ff-a535-4b69-9144-e06275e01e35.jpg  pain_au_chocolat    130  test   \n",
       "\n",
       "  clear_or_confusing whole_food_or_dish one_food_or_multiple  \\\n",
       "0                NaN                NaN                  NaN   \n",
       "1                NaN                NaN                  NaN   \n",
       "2                NaN                NaN                  NaN   \n",
       "3                NaN                NaN                  NaN   \n",
       "4                NaN                NaN                  NaN   \n",
       "\n",
       "  label_last_updated_at label_source       image_source  \n",
       "0                   NaN          NaN  internet_download  \n",
       "1                   NaN          NaN  internet_download  \n",
       "2                   NaN          NaN  internet_download  \n",
       "3                   NaN          NaN  internet_download  \n",
       "4                   NaN          NaN  internet_download  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filename',\n",
       " 'image_name',\n",
       " 'class_name',\n",
       " 'label',\n",
       " 'split',\n",
       " 'clear_or_confusing',\n",
       " 'whole_food_or_dish',\n",
       " 'one_food_or_multiple',\n",
       " 'label_last_updated_at',\n",
       " 'label_source',\n",
       " 'image_source']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.annotations_columns_to_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tomato            469\n",
       "banana            415\n",
       "lemon             394\n",
       "onion_brown       393\n",
       "cucumber          375\n",
       "                 ... \n",
       "guacamole         100\n",
       "bread_naan         67\n",
       "prosciutto         62\n",
       "curry_chicken      60\n",
       "fruit_smoothie     56\n",
       "Name: class_name, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the value counts of the class_name column\n",
    "updated_annotations['class_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Exporting the following columns to updated_annotations.csv: ['filename', 'image_name', 'class_name', 'label', 'split', 'clear_or_confusing', 'whole_food_or_dish', 'one_food_or_multiple', 'label_last_updated_at', 'label_source', 'image_source']\n",
      "[INFO] 40325 changes to annotations.csv, updated label files and original annotations are different, saving the updated annotations.csv\n",
      "[INFO] Uploading updated_annotations.csv to updated_annotations.csv...\n",
      "[INFO] Connected to Google Storage bucket: food_vision_bucket_with_object_versioning\n",
      "[INFO] File updated_annotations.csv uploaded to food_vision_bucket_with_object_versioning/updated_annotations.csv.\n",
      "[INFO] File size: 6791222 bytes\n",
      "[INFO] Blob annotations.csv has been renamed to old_annotations/2023-02-15_16-29-36_old_annotations.csv\n",
      "[INFO] Blob updated_annotations.csv has been renamed to annotations.csv\n",
      "[INFO] Logging 'food_vision_labels' from 'gs://food_vision_bucket_with_object_versioning/annotations.csv' to Weights & Biases...\n"
     ]
    }
   ],
   "source": [
    "# Upload the updated annotations to Google Storage and track the changes\n",
    "import os\n",
    "from utils.gcp_utils import upload_to_gs, rename_blob, delete_blob\n",
    "from utils.wandb_utils import wandb_add_artifact_with_reference\n",
    "from utils.misc import get_now_time\n",
    "\n",
    "UPDATED_ANNOTATIONS_TARGET_FILENAME = \"updated_annotations.csv\"\n",
    "ORIGINAL_ANNOTATIONS_TARGET_FILENAME = \"annotations.csv\"\n",
    "GS_BUCKET_NAME = config.gs_bucket_name\n",
    "\n",
    "# Export the updated annotations to a CSV\n",
    "columns_to_export = config.annotations_columns_to_export\n",
    "print(f\"[INFO] Exporting the following columns to {UPDATED_ANNOTATIONS_TARGET_FILENAME}: {columns_to_export}\")\n",
    "\n",
    "# TODO: Check if the updated_annotations_reset_index and the original_annotations actually differ, if so save them and upload them, else exit\n",
    "if num_differences > 0:\n",
    "    print(f\"[INFO] {num_differences} changes to annotations.csv, updated label files and original annotations are different, saving the updated annotations.csv\")\n",
    "\n",
    "    # Export the updated_annotations_reset_index to a csv\n",
    "    updated_annotations[columns_to_export].to_csv(UPDATED_ANNOTATIONS_TARGET_FILENAME, index=False)\n",
    "\n",
    "    # Upload the updated CSV to Google Storage\n",
    "    upload_to_gs(bucket_name=GS_BUCKET_NAME, \n",
    "                 source_file_name=UPDATED_ANNOTATIONS_TARGET_FILENAME, \n",
    "                 destination_blob_name=UPDATED_ANNOTATIONS_TARGET_FILENAME)\n",
    "\n",
    "    # Rename the old CSV on Google Storage\n",
    "    bucket_to_move_old_annotations_to = \"old_annotations\"\n",
    "    name_to_rename_old_annotations = os.path.join(bucket_to_move_old_annotations_to, f\"{get_now_time()}_old_annotations.csv\")\n",
    "\n",
    "    rename_blob(bucket_name=GS_BUCKET_NAME,\n",
    "                blob_name=ORIGINAL_ANNOTATIONS_TARGET_FILENAME,\n",
    "                new_name=name_to_rename_old_annotations)\n",
    "\n",
    "    # Rename the \"updated_annotations.csv\" on Google Storage to \"annotations.csv\" \n",
    "    rename_blob(bucket_name=GS_BUCKET_NAME,\n",
    "                blob_name=UPDATED_ANNOTATIONS_TARGET_FILENAME,\n",
    "                new_name=ORIGINAL_ANNOTATIONS_TARGET_FILENAME)\n",
    "\n",
    "    # Track the changes in the annotations with Weights & Biases\n",
    "    annotations_path_on_gcs = f\"gs://{GS_BUCKET_NAME}/{ORIGINAL_ANNOTATIONS_TARGET_FILENAME}\"\n",
    "    wandb_add_artifact_with_reference(wandb_run=run,\n",
    "                                      artifact_name=\"food_vision_labels\",\n",
    "                                      artifact_type=\"labels\",\n",
    "                                      description=\"Labels for FoodVision project\",\n",
    "                                      reference_path=annotations_path_on_gcs)\n",
    "else:\n",
    "    print(\"[INFO] No changes to annotations.csv, updated label files and original annotations are the same, try fixing/updating the label files and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'almond_butter',\n",
       " 1: 'almonds',\n",
       " 2: 'apple_green',\n",
       " 3: 'apple_red',\n",
       " 4: 'apricot',\n",
       " 5: 'asparagus',\n",
       " 6: 'avocado',\n",
       " 7: 'bacon',\n",
       " 8: 'bacon_and_egg_burger',\n",
       " 9: 'bagel',\n",
       " 10: 'baklava',\n",
       " 11: 'banana',\n",
       " 12: 'banana_bread',\n",
       " 13: 'barbecue_sauce',\n",
       " 14: 'beans',\n",
       " 15: 'beef',\n",
       " 16: 'beef_curry',\n",
       " 17: 'beef_mince',\n",
       " 18: 'beef_stir_fry',\n",
       " 19: 'beer',\n",
       " 20: 'beetroot',\n",
       " 21: 'biltong',\n",
       " 22: 'blackberries',\n",
       " 23: 'blueberries',\n",
       " 24: 'bok_choy',\n",
       " 25: 'bread',\n",
       " 26: 'bread_naan',\n",
       " 27: 'broccoli',\n",
       " 28: 'broccolini',\n",
       " 29: 'brownie',\n",
       " 30: 'brussel_sprouts',\n",
       " 31: 'burrito',\n",
       " 32: 'butter',\n",
       " 33: 'cabbage',\n",
       " 34: 'calamari',\n",
       " 35: 'candy',\n",
       " 36: 'capsicum',\n",
       " 37: 'carrot',\n",
       " 38: 'cashews',\n",
       " 39: 'cauliflower',\n",
       " 40: 'celery',\n",
       " 41: 'cheese',\n",
       " 42: 'cheeseburger',\n",
       " 43: 'cherries',\n",
       " 44: 'chicken_breast',\n",
       " 45: 'chicken_thighs',\n",
       " 46: 'chicken_wings',\n",
       " 47: 'chilli',\n",
       " 48: 'chimichurri',\n",
       " 49: 'chocolate',\n",
       " 50: 'chocolate_cake',\n",
       " 51: 'coconut',\n",
       " 52: 'coffee',\n",
       " 53: 'coleslaw',\n",
       " 54: 'cookies',\n",
       " 55: 'coriander',\n",
       " 56: 'corn',\n",
       " 57: 'corn_chips',\n",
       " 58: 'cream',\n",
       " 59: 'croissant',\n",
       " 60: 'crumbed_chicken',\n",
       " 61: 'cucumber',\n",
       " 62: 'cupcake',\n",
       " 63: 'curry_chicken',\n",
       " 64: 'daikon_radish',\n",
       " 65: 'dates',\n",
       " 66: 'donuts',\n",
       " 67: 'dragonfruit',\n",
       " 68: 'eggplant',\n",
       " 69: 'eggs',\n",
       " 70: 'enoki_mushroom',\n",
       " 71: 'fennel',\n",
       " 72: 'figs',\n",
       " 73: 'french_toast',\n",
       " 74: 'fried_rice',\n",
       " 75: 'fries',\n",
       " 76: 'fruit_juice',\n",
       " 77: 'fruit_smoothie',\n",
       " 78: 'garlic',\n",
       " 79: 'garlic_bread',\n",
       " 80: 'ginger',\n",
       " 81: 'goji_berries',\n",
       " 82: 'granola',\n",
       " 83: 'grapefruit',\n",
       " 84: 'grapes_black',\n",
       " 85: 'grapes_red',\n",
       " 86: 'grapes_white',\n",
       " 87: 'green_beans',\n",
       " 88: 'guacamole',\n",
       " 89: 'guava',\n",
       " 90: 'gyoza',\n",
       " 91: 'ham',\n",
       " 92: 'honey',\n",
       " 93: 'hot_chocolate',\n",
       " 94: 'ice_coffee',\n",
       " 95: 'ice_cream',\n",
       " 96: 'iceberg_lettuce',\n",
       " 97: 'jerusalem_artichoke',\n",
       " 98: 'kale',\n",
       " 99: 'karaage_chicken',\n",
       " 100: 'kimchi',\n",
       " 101: 'kiwi_fruit',\n",
       " 102: 'lamb_chops',\n",
       " 103: 'leek',\n",
       " 104: 'lemon',\n",
       " 105: 'lentils',\n",
       " 106: 'lettuce',\n",
       " 107: 'lime',\n",
       " 108: 'lychee',\n",
       " 109: 'mandarin',\n",
       " 110: 'mango',\n",
       " 111: 'maple_syrup',\n",
       " 112: 'mashed_potato',\n",
       " 113: 'mayonnaise',\n",
       " 114: 'milk',\n",
       " 115: 'miso_soup',\n",
       " 116: 'mushrooms',\n",
       " 117: 'nectarines',\n",
       " 118: 'noodles',\n",
       " 119: 'nuts',\n",
       " 120: 'olive_oil',\n",
       " 121: 'olives',\n",
       " 122: 'omelette',\n",
       " 123: 'onion_brown',\n",
       " 124: 'onion_green',\n",
       " 125: 'onion_red',\n",
       " 126: 'onion_white',\n",
       " 127: 'orange',\n",
       " 128: 'orange_juice',\n",
       " 129: 'oysters',\n",
       " 130: 'pain_au_chocolat',\n",
       " 131: 'pancakes',\n",
       " 132: 'papaya',\n",
       " 133: 'parsley',\n",
       " 134: 'parsnips',\n",
       " 135: 'passionfruit',\n",
       " 136: 'pasta',\n",
       " 137: 'pawpaw',\n",
       " 138: 'peach',\n",
       " 139: 'pear',\n",
       " 140: 'peas',\n",
       " 141: 'pickles',\n",
       " 142: 'pineapple',\n",
       " 143: 'pizza',\n",
       " 144: 'plum',\n",
       " 145: 'pomegranate',\n",
       " 146: 'popcorn',\n",
       " 147: 'pork_belly',\n",
       " 148: 'pork_chop',\n",
       " 149: 'pork_loins',\n",
       " 150: 'porridge',\n",
       " 151: 'potato_bake',\n",
       " 152: 'potato_brown',\n",
       " 153: 'potato_chips',\n",
       " 154: 'potato_scallop',\n",
       " 155: 'potato_white',\n",
       " 156: 'prawns',\n",
       " 157: 'prosciutto',\n",
       " 158: 'pumpkin',\n",
       " 159: 'radish',\n",
       " 160: 'ramen',\n",
       " 161: 'raspberries',\n",
       " 162: 'red_wine',\n",
       " 163: 'rhubarb',\n",
       " 164: 'rice',\n",
       " 165: 'roast_beef',\n",
       " 166: 'roast_pork',\n",
       " 167: 'roast_potatoes',\n",
       " 168: 'rockmelon',\n",
       " 169: 'rosemary',\n",
       " 170: 'salad',\n",
       " 171: 'salami',\n",
       " 172: 'salmon',\n",
       " 173: 'salsa',\n",
       " 174: 'salt',\n",
       " 175: 'sandwich',\n",
       " 176: 'sardines',\n",
       " 177: 'sausage_roll',\n",
       " 178: 'sausages',\n",
       " 179: 'scrambled_eggs',\n",
       " 180: 'seaweed',\n",
       " 181: 'shallots',\n",
       " 182: 'snow_peas',\n",
       " 183: 'soda',\n",
       " 184: 'soy_sauce',\n",
       " 185: 'spaghetti_bolognese',\n",
       " 186: 'spinach',\n",
       " 187: 'sports_drink',\n",
       " 188: 'squash',\n",
       " 189: 'starfruit',\n",
       " 190: 'steak',\n",
       " 191: 'strawberries',\n",
       " 192: 'sushi',\n",
       " 193: 'sweet_potato',\n",
       " 194: 'tacos',\n",
       " 195: 'tamarillo',\n",
       " 196: 'taro',\n",
       " 197: 'tea',\n",
       " 198: 'toast',\n",
       " 199: 'tofu',\n",
       " 200: 'tomato',\n",
       " 201: 'tomato_chutney',\n",
       " 202: 'tomato_sauce',\n",
       " 203: 'turnip',\n",
       " 204: 'watermelon',\n",
       " 205: 'white_wine',\n",
       " 206: 'yoghurt',\n",
       " 207: 'zucchini'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn class_name and label into a dictionary\n",
    "class_name_to_label_dict = dict(zip(updated_annotations.class_name, updated_annotations.label))\n",
    "\n",
    "# Reverse and sort the dictionary\n",
    "class_dict_updated = {v: k for k, v in class_name_to_label_dict.items()}\n",
    "\n",
    "# Sort the class dict alphabetically\n",
    "class_dict_updated = dict(sorted(class_dict_updated.items()))\n",
    "\n",
    "class_dict_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export class_dict to JSON\n",
    "import json\n",
    "with open(\"class_dict.json\", \"w\") as f:\n",
    "    json.dump(class_dict_updated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'almond_butter',\n",
       " 1: 'almonds',\n",
       " 2: 'apple_green',\n",
       " 3: 'apple_red',\n",
       " 4: 'apricot',\n",
       " 5: 'asparagus',\n",
       " 6: 'avocado',\n",
       " 7: 'bacon',\n",
       " 8: 'bacon_and_egg_burger',\n",
       " 9: 'bagel',\n",
       " 10: 'baklava',\n",
       " 11: 'banana',\n",
       " 12: 'banana_bread',\n",
       " 13: 'barbecue_sauce',\n",
       " 14: 'beans',\n",
       " 15: 'beef',\n",
       " 16: 'beef_curry',\n",
       " 17: 'beef_mince',\n",
       " 18: 'beef_stir_fry',\n",
       " 19: 'beer',\n",
       " 20: 'beetroot',\n",
       " 21: 'biltong',\n",
       " 22: 'blackberries',\n",
       " 23: 'blueberries',\n",
       " 24: 'bok_choy',\n",
       " 25: 'bread',\n",
       " 26: 'bread_naan',\n",
       " 27: 'broccoli',\n",
       " 28: 'broccolini',\n",
       " 29: 'brownie',\n",
       " 30: 'brussel_sprouts',\n",
       " 31: 'burrito',\n",
       " 32: 'butter',\n",
       " 33: 'cabbage',\n",
       " 34: 'calamari',\n",
       " 35: 'candy',\n",
       " 36: 'capsicum',\n",
       " 37: 'carrot',\n",
       " 38: 'cashews',\n",
       " 39: 'cauliflower',\n",
       " 40: 'celery',\n",
       " 41: 'cheese',\n",
       " 42: 'cheeseburger',\n",
       " 43: 'cherries',\n",
       " 44: 'chicken_breast',\n",
       " 45: 'chicken_thighs',\n",
       " 46: 'chicken_wings',\n",
       " 47: 'chilli',\n",
       " 48: 'chimichurri',\n",
       " 49: 'chocolate',\n",
       " 50: 'chocolate_cake',\n",
       " 51: 'coconut',\n",
       " 52: 'coffee',\n",
       " 53: 'coleslaw',\n",
       " 54: 'cookies',\n",
       " 55: 'coriander',\n",
       " 56: 'corn',\n",
       " 57: 'corn_chips',\n",
       " 58: 'cream',\n",
       " 59: 'croissant',\n",
       " 60: 'crumbed_chicken',\n",
       " 61: 'cucumber',\n",
       " 62: 'cupcake',\n",
       " 63: 'curry_chicken',\n",
       " 64: 'daikon_radish',\n",
       " 65: 'dates',\n",
       " 66: 'donuts',\n",
       " 67: 'dragonfruit',\n",
       " 68: 'eggplant',\n",
       " 69: 'eggs',\n",
       " 70: 'enoki_mushroom',\n",
       " 71: 'fennel',\n",
       " 72: 'figs',\n",
       " 73: 'french_toast',\n",
       " 74: 'fried_rice',\n",
       " 75: 'fries',\n",
       " 76: 'fruit_juice',\n",
       " 77: 'fruit_smoothie',\n",
       " 78: 'garlic',\n",
       " 79: 'garlic_bread',\n",
       " 80: 'ginger',\n",
       " 81: 'goji_berries',\n",
       " 82: 'granola',\n",
       " 83: 'grapefruit',\n",
       " 84: 'grapes_black',\n",
       " 85: 'grapes_red',\n",
       " 86: 'grapes_white',\n",
       " 87: 'green_beans',\n",
       " 88: 'guacamole',\n",
       " 89: 'guava',\n",
       " 90: 'gyoza',\n",
       " 91: 'ham',\n",
       " 92: 'honey',\n",
       " 93: 'hot_chocolate',\n",
       " 94: 'ice_coffee',\n",
       " 95: 'ice_cream',\n",
       " 96: 'iceberg_lettuce',\n",
       " 97: 'jerusalem_artichoke',\n",
       " 98: 'kale',\n",
       " 99: 'karaage_chicken',\n",
       " 100: 'kimchi',\n",
       " 101: 'kiwi_fruit',\n",
       " 102: 'lamb_chops',\n",
       " 103: 'leek',\n",
       " 104: 'lemon',\n",
       " 105: 'lentils',\n",
       " 106: 'lettuce',\n",
       " 107: 'lime',\n",
       " 108: 'lychee',\n",
       " 109: 'mandarin',\n",
       " 110: 'mango',\n",
       " 111: 'maple_syrup',\n",
       " 112: 'mashed_potato',\n",
       " 113: 'mayonnaise',\n",
       " 114: 'milk',\n",
       " 115: 'miso_soup',\n",
       " 116: 'mushrooms',\n",
       " 117: 'nectarines',\n",
       " 118: 'noodles',\n",
       " 119: 'nuts',\n",
       " 120: 'olive_oil',\n",
       " 121: 'olives',\n",
       " 122: 'omelette',\n",
       " 123: 'onion_brown',\n",
       " 124: 'onion_green',\n",
       " 125: 'onion_red',\n",
       " 126: 'onion_white',\n",
       " 127: 'orange',\n",
       " 128: 'orange_juice',\n",
       " 129: 'oysters',\n",
       " 130: 'pain_au_chocolat',\n",
       " 131: 'pancakes',\n",
       " 132: 'papaya',\n",
       " 133: 'parsley',\n",
       " 134: 'parsnips',\n",
       " 135: 'passionfruit',\n",
       " 136: 'pasta',\n",
       " 137: 'pawpaw',\n",
       " 138: 'peach',\n",
       " 139: 'pear',\n",
       " 140: 'peas',\n",
       " 141: 'pickles',\n",
       " 142: 'pineapple',\n",
       " 143: 'pizza',\n",
       " 144: 'plum',\n",
       " 145: 'pomegranate',\n",
       " 146: 'popcorn',\n",
       " 147: 'pork_belly',\n",
       " 148: 'pork_chop',\n",
       " 149: 'pork_loins',\n",
       " 150: 'porridge',\n",
       " 151: 'potato_bake',\n",
       " 152: 'potato_brown',\n",
       " 153: 'potato_chips',\n",
       " 154: 'potato_scallop',\n",
       " 155: 'potato_white',\n",
       " 156: 'prawns',\n",
       " 157: 'prosciutto',\n",
       " 158: 'pumpkin',\n",
       " 159: 'radish',\n",
       " 160: 'ramen',\n",
       " 161: 'raspberries',\n",
       " 162: 'red_wine',\n",
       " 163: 'rhubarb',\n",
       " 164: 'rice',\n",
       " 165: 'roast_beef',\n",
       " 166: 'roast_pork',\n",
       " 167: 'roast_potatoes',\n",
       " 168: 'rockmelon',\n",
       " 169: 'rosemary',\n",
       " 170: 'salad',\n",
       " 171: 'salami',\n",
       " 172: 'salmon',\n",
       " 173: 'salsa',\n",
       " 174: 'salt',\n",
       " 175: 'sandwich',\n",
       " 176: 'sardines',\n",
       " 177: 'sausage_roll',\n",
       " 178: 'sausages',\n",
       " 179: 'scrambled_eggs',\n",
       " 180: 'seaweed',\n",
       " 181: 'shallots',\n",
       " 182: 'snow_peas',\n",
       " 183: 'soda',\n",
       " 184: 'soy_sauce',\n",
       " 185: 'spaghetti_bolognese',\n",
       " 186: 'spinach',\n",
       " 187: 'sports_drink',\n",
       " 188: 'squash',\n",
       " 189: 'starfruit',\n",
       " 190: 'steak',\n",
       " 191: 'strawberries',\n",
       " 192: 'sushi',\n",
       " 193: 'sweet_potato',\n",
       " 194: 'tacos',\n",
       " 195: 'tamarillo',\n",
       " 196: 'taro',\n",
       " 197: 'tea',\n",
       " 198: 'toast',\n",
       " 199: 'tofu',\n",
       " 200: 'tomato',\n",
       " 201: 'tomato_chutney',\n",
       " 202: 'tomato_sauce',\n",
       " 203: 'turnip',\n",
       " 204: 'watermelon',\n",
       " 205: 'white_wine',\n",
       " 206: 'yoghurt',\n",
       " 207: 'zucchini'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn class_dict into a DataFrame\n",
    "class_dict_df = pd.DataFrame(class_dict_updated.items(), columns=[\"label\", \"class_name\"])\n",
    "\n",
    "# Export to csv\n",
    "class_dict_df.to_csv(\"class_dict.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>almond_butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>almonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>apple_green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>apple_red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>apricot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>turnip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>205</td>\n",
       "      <td>white_wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>206</td>\n",
       "      <td>yoghurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>zucchini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     class_name\n",
       "0        0  almond_butter\n",
       "1        1        almonds\n",
       "2        2    apple_green\n",
       "3        3      apple_red\n",
       "4        4        apricot\n",
       "..     ...            ...\n",
       "203    203         turnip\n",
       "204    204     watermelon\n",
       "205    205     white_wine\n",
       "206    206        yoghurt\n",
       "207    207       zucchini\n",
       "\n",
       "[208 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
